# -*- coding: utf-8 -*-
"""task2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p7hNZpLLvRl0h8CM3pNvhEcFtx9_jAff
"""

!pip install opencv-python-headless numpy matplotlib

import cv2
import numpy as np
import os
import time
from google.colab import files
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt
from IPython.display import HTML, display
import io
import base64
from IPython.display import clear_output

class DroneMotionTracker:
    def __init__(self):
        # Drone pozisyonu (x, y, z düzlemi)
        self.current_position = np.array([0.0, 0.0, 0.0])
        self.prev_position = np.array([0.0, 0.0, 0.0])

        # Kalman filtresi kurulumu (x, y, z, vx, vy, vz)
        self.kalman = cv2.KalmanFilter(6, 3)  # 6 durum (x, y, z, vx, vy, vz), 3 ölçüm (x, y, z)
        self.kalman.measurementMatrix = np.eye(3, 6, dtype=np.float32)
        self.kalman.transitionMatrix = np.array([[1, 0, 0, 1, 0, 0],
                                                 [0, 1, 0, 0, 1, 0],
                                                 [0, 0, 1, 0, 0, 1],
                                                 [0, 0, 0, 1, 0, 0],
                                                 [0, 0, 0, 0, 1, 0],
                                                 [0, 0, 0, 0, 0, 1]], np.float32)

        # Kalman filtresi parametrelerini iyileştir
        self.kalman.processNoiseCov = np.eye(6, dtype=np.float32) * 0.01
        self.kalman.measurementNoiseCov = np.eye(3, dtype=np.float32) * 0.1
        self.kalman.errorCovPost = np.eye(6, dtype=np.float32) * 0.1

        # Pozisyon geçmişi
        self.position_history = []

        # Önceki kare ve gri tonlamalı görüntü
        self.prev_frame = None
        self.prev_gray = None

        # İyi özellik noktaları için parametreler
        self.feature_params = dict(maxCorners=100,
                                   qualityLevel=0.3,
                                   minDistance=7,
                                   blockSize=7)

        # Optik akış için parametreler
        self.lk_params = dict(winSize=(15, 15),
                              maxLevel=2,
                              criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

        # İzlenen noktalar
        self.tracks = []
        self.track_len = 10

        # Sabit referans noktaları
        self.reference_points = []
        self.reference_tracks = []

        # Hareket yönü
        self.movement_direction = None

        # Toplam hareket vektörü
        self.total_movement = np.array([0.0, 0.0, 0.0])

        # Dönüş açısı
        self.rotation_angle = 0.0

    def calibrate_camera(self, frame):
        """Camera calibration for perspective correction"""
        height, width = frame.shape[:2]
        camera_matrix = np.array([
            [width, 0, width/2],
            [0, width, height/2],
            [0, 0, 1]
        ], dtype=np.float32)
        return camera_matrix

    def detect_features(self, frame):
        """Görüntüdeki iyi özellikleri tespit et"""
        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        p = cv2.goodFeaturesToTrack(frame_gray, mask=None, **self.feature_params)

        if p is not None:
            for x, y in p.reshape(-1, 2):
                self.tracks.append([(x, y)])

        return frame_gray

    def calculate_optical_flow(self, frame):
        """Optik akışı hesapla"""
        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        if len(self.tracks) > 0:
            p0 = np.float32([tr[-1] for tr in self.tracks]).reshape(-1, 1, 2)

            p1, st, err = cv2.calcOpticalFlowPyrLK(self.prev_gray, frame_gray, p0, None, **self.lk_params)

            p0r, st, err = cv2.calcOpticalFlowPyrLK(frame_gray, self.prev_gray, p1, None, **self.lk_params)

            d = abs(p0-p0r).reshape(-1, 2).max(-1)
            good = d < 1

            new_tracks = []

            movement_vector = np.array([0.0, 0.0])
            valid_points = 0

            for tr, (x, y), good_flag in zip(self.tracks, p1.reshape(-1, 2), good):
                if not good_flag:
                    continue

                tr.append((x, y))

                if len(tr) > self.track_len:
                    del tr[0]

                new_tracks.append(tr)

                if len(tr) > 1:
                    dx = tr[-1][0] - tr[-2][0]
                    dy = tr[-1][1] - tr[-2][1]
                    movement_vector += np.array([dx, dy])
                    valid_points += 1

            self.tracks = new_tracks

            if valid_points > 0:
                movement_vector /= valid_points

                self.total_movement[:2] += movement_vector

                measured_pos = self.current_position[:2].copy() - movement_vector

                self.kalman.predict()
                measurement = np.array([[measured_pos[0]], [measured_pos[1]], [0]], dtype=np.float32)
                corrected = self.kalman.correct(measurement)

                self.prev_position[:2] = self.current_position[:2].copy()
                self.current_position[:2] = np.array([corrected[0,0], corrected[1,0]])

                self.position_history.append(self.current_position.copy())
                if len(self.position_history) > 100:
                    self.position_history.pop(0)

                # Hareket yönünü heapla ve dzelt
                angle = np.arctan2(movement_vector[1], movement_vector[0])
                angle_deg = np.degrees(angle)

                # Ölçülen hareketin büyüklüğüne göre dönüş açısını ağırlıklandır
                movement_magnitude = np.linalg.norm(movement_vector)

                # Dönüş açısını hesapla (açısal hız) - daha hassas algılama
                if len(self.tracks) > 5 and movement_magnitude > 0.5:
                    center = np.mean(np.array([tr[-1] for tr in self.tracks]), axis=0)

                    angles = []
                    weights = []

                    for tr in self.tracks:
                        if len(tr) > 1:
                            v1 = np.array(tr[-2]) - center
                            v2 = np.array(tr[-1]) - center

                            if np.linalg.norm(v1) < 1 or np.linalg.norm(v2) < 1:
                                continue

                            dot = np.dot(v1, v2)
                            det = v1[0] * v2[1] - v1[1] * v2[0]
                            angle = np.arctan2(det, dot)

                            weight = np.linalg.norm(v1) + np.linalg.norm(v2)
                            angles.append(angle)
                            weights.append(weight)

                    if angles:
                        self.rotation_angle = np.average(angles, weights=weights) if sum(weights) > 0 else np.mean(angles)

                # Yön bilgisini güncelle
                if -30 <= angle_deg <= 30:
                    self.movement_direction = "Sola"
                elif 30 < angle_deg <= 60:
                    self.movement_direction = "Sol-Aşağı"
                elif 60 < angle_deg <= 120:
                    self.movement_direction = "Aşağı"
                elif 120 < angle_deg <= 150:
                    self.movement_direction = "Sağ-Aşağı"
                elif angle_deg > 150 or angle_deg < -150:
                    self.movement_direction = "Sağa"
                elif -150 <= angle_deg < -120:
                    self.movement_direction = "Sağ-Yukarı"
                elif -120 <= angle_deg < -60:
                    self.movement_direction = "Yukarı"
                else:
                    self.movement_direction = "Sol-Yukarı"

        # Yeni özellikler ekle
        if len(self.tracks) < 30:
            mask = np.zeros_like(frame_gray)
            mask[:] = 255

            for x, y in [np.int32(tr[-1]) for tr in self.tracks]:
                cv2.circle(mask, (x, y), 5, 0, -1)

            p = cv2.goodFeaturesToTrack(frame_gray, mask=mask, **self.feature_params)

            if p is not None:
                for x, y in p.reshape(-1, 2):
                    self.tracks.append([(x, y)])

        self.prev_gray = frame_gray

    def calculate_health(self, frame):
        """Calculate health value of position tracking (0-1)"""
        if len(self.tracks) < 10:
            return 0.0  # Not enough tracking points

        # Calculate feature point consistency
        consistency = min(1.0, len(self.tracks) / 50.0)

        # Check if movement is within expected range
        movement_magnitude = np.linalg.norm(self.current_position[:2] - self.prev_position[:2])
        movement_health = 1.0 if 0.0 <= movement_magnitude <= 5.0 else 0.5

        # Final health is a combination of factors
        health = (consistency * 0.6) + (movement_health * 0.4)
        return health

    def update_position(self, frame):
        """Drone pozisyonunu güncelle"""
        height, width, _ = frame.shape

        # İlk kare ise
        if self.prev_gray is None:
            self.prev_gray = self.detect_features(frame)
            return frame

        # Optik akışı hesapla
        self.calculate_optical_flow(frame)

        # Sağlık değerini hesapla
        health = self.calculate_health(frame)

        # İzlenen noktaları çiz
        for tr in self.tracks:
            for i in range(1, len(tr)):
                intensity = int(255 * (1 - i / len(tr)))
                color = (0, intensity + 100, 0)
                cv2.line(frame, tuple(map(int, tr[i-1])), tuple(map(int, tr[i])), color, 2)

            cv2.circle(frame, tuple(map(int, tr[-1])), 3, (0, 255, 0), -1)

        # Drone'un tahmini konumunu çiz
        center_x, center_y = width // 2, height // 2
        drone_x = int(center_x + self.current_position[0] * 20)
        drone_y = int(center_y + self.current_position[1] * 20)

        drone_size = 25

        cv2.circle(frame, (drone_x, drone_y), drone_size//2, (0, 0, 255), 2)

        if self.movement_direction:
            direction_angle = 0
            if self.movement_direction == "Yukarı":
                direction_angle = -90
            elif self.movement_direction == "Sağa":
                direction_angle = 0
            elif self.movement_direction == "Aşağı":
                direction_angle = 90
            elif self.movement_direction == "Sola":
                direction_angle = 180
            elif "Yukarı" in self.movement_direction and "Sağ" in self.movement_direction:
                direction_angle = -45
            elif "Yukarı" in self.movement_direction and "Sol" in self.movement_direction:
                direction_angle = -135
            elif "Aşağı" in self.movement_direction and "Sağ" in self.movement_direction:
                direction_angle = 45
            elif "Aşağı" in self.movement_direction and "Sol" in self.movement_direction:
                direction_angle = 135

            rad = np.radians(direction_angle)
            arrow_length = drone_size
            end_x = int(drone_x + arrow_length * np.cos(rad))
            end_y = int(drone_y + arrow_length * np.sin(rad))

            cv2.arrowedLine(frame, (drone_x, drone_y), (end_x, end_y), (0, 0, 255), 2, tipLength=0.3)

        if len(self.position_history) > 1:
            for i in range(1, len(self.position_history)):
                start_x = int(center_x + self.position_history[i-1][0] * 20)
                start_y = int(center_y + self.position_history[i-1][1] * 20)
                end_x = int(center_x + self.position_history[i][0] * 20)
                end_y = int(center_y + self.position_history[i][1] * 20)

                intensity = int(255 * i / len(self.position_history))
                color = (0, 0, min(255, intensity + 100))

                cv2.line(frame, (start_x, start_y), (end_x, end_y), color, 2)

        info_panel = np.zeros((120, 300, 3), dtype=np.uint8)
        cv2.rectangle(info_panel, (0, 0), (300, 120), (45, 45, 45), -1)
        cv2.putText(info_panel, f"X: {self.current_position[0]:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (50, 205, 255), 2)
        cv2.putText(info_panel, f"Y: {self.current_position[1]:.2f}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (50, 205, 255), 2)
        cv2.putText(info_panel, f"Health: {health:.2f}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (50, 205, 255), 2)

        if self.movement_direction:
            cv2.putText(info_panel, f"Yön: {self.movement_direction}", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (50, 205, 255), 2)

        rotation_deg = np.degrees(self.rotation_angle)
        cv2.putText(info_panel, f"Dönüş: {rotation_deg:.2f}°", (150, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (50, 205, 255), 2)

        frame[10:130, 10:310] = info_panel

        cv2.arrowedLine(frame, (center_x, center_y), (center_x + 100, center_y), (0, 0, 255), 2)
        cv2.putText(frame, "X", (center_x + 110, center_y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

        cv2.arrowedLine(frame, (center_x, center_y), (center_x, center_y - 100), (0, 255, 0), 2)
        cv2.putText(frame, "Y", (center_x - 10, center_y - 110), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        return frame

    def get_position(self):
        """Güncel pozisyonu döndür"""
        return self.current_position

def upload_video():
    """Kullanıcıdan video yüklemesi iste"""
    uploaded = files.upload()
    for filename in uploaded.keys():
        print(f"Video yüklendi: {filename}")
        return filename
    return None

def plot_position_history(position_history):
    """Pozisyon geçmişini grafikle göster"""
    if not position_history:
        print("Pozisyon geçmişi boş!")
        return

    x = [pos[0] for pos in position_history]
    y = [pos[1] for pos in position_history]

    plt.figure(figsize=(10, 8))

    # X-Y düzlemi (üstten görünüm)
    plt.plot(x, y, 'r-', linewidth=2)  # Kırmızı çizgi
    plt.scatter(x[-1], y[-1], c='blue', s=100, label='Son Konum')  # Son konum
    plt.scatter(x[0], y[0], c='green', s=100, label='Başlangıç Konumu')  # Başlangıç konumu

    # Hareket yönü oklarını iyileştir - daha sık ve belirgin ok çiz
    for i in range(0, len(x)-1, 3):  # Her 3 noktada bir ok çiz (daha sık)
        if i+1 < len(x):  # Dizin sınırlarını kontrol et
            dx = x[i+1] - x[i]
            dy = y[i+1] - y[i]
            magnitude = np.sqrt(dx**2 + dy**2)
            head_size = max(0.05, min(0.2, magnitude * 0.1))
            plt.arrow(x[i], y[i], dx, dy, head_width=head_size, head_length=head_size*2,
                     fc='blue', ec='blue', alpha=0.7)

    plt.arrow(0, 0, 1, 0, head_width=0.1, head_length=0.2, fc='red', ec='red')
    plt.arrow(0, 0, 0, 1, head_width=0.1, head_length=0.2, fc='green', ec='green')
    plt.text(1.1, 0, "X Ekseni", color='red', fontsize=10)
    plt.text(0, 1.1, "Y Ekseni", color='green', fontsize=10)

    plt.title('Drone Hareketi (X-Y Düzlemi)')
    plt.xlabel('X Pozisyonu')
    plt.ylabel('Y Pozisyonu')
    plt.grid(True)
    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)
    plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)
    plt.legend()

    max_range = max(max(abs(np.array(x))), max(abs(np.array(y)))) + 1
    plt.xlim(-max_range, max_range)
    plt.ylim(-max_range, max_range)

    plt.tight_layout()
    plt.show()


    plt.figure(figsize=(12, 10))

    plt.subplot(2, 1, 1)
    plt.plot(range(len(x)), x, 'r-')
    plt.title('X Pozisyonu - Zaman')
    plt.xlabel('Kare')
    plt.ylabel('X Pozisyonu')
    plt.grid(True)

    plt.subplot(2, 1, 2)
    plt.plot(range(len(y)), y, 'g-')
    plt.title('Y Pozisyonu - Zaman')
    plt.xlabel('Kare')
    plt.ylabel('Y Pozisyonu')
    plt.grid(True)

    plt.tight_layout()
    plt.show()

    if len(position_history) > 1:
        plt.figure(figsize=(12, 6))

        dx = np.diff([pos[0] for pos in position_history])
        dy = np.diff([pos[1] for pos in position_history])
        speed = np.sqrt(dx**2 + dy**2)

        plt.plot(range(len(speed)), speed, 'b-')
        plt.title('Hız - Zaman')
        plt.xlabel('Kare')
        plt.ylabel('Hız (birim/kare)')
        plt.grid(True)
        plt.tight_layout()
        plt.show()

def analyze_trajectory(position_history):
    """Hareket yörüngesini analiz et"""
    if len(position_history) < 10:
        print("Yeterli veri yok!")
        return

    x = np.array([pos[0] for pos in position_history])
    y = np.array([pos[1] for pos in position_history])

    dx = np.diff(x)
    dy = np.diff(y)
    total_distance = np.sum(np.sqrt(dx**2 + dy**2))

    direct_distance = np.sqrt((x[-1] - x[0])**2 + (y[-1] - y[0])**2)

    linearity = direct_distance / total_distance if total_distance > 0 else 0

    avg_speed = total_distance / len(position_history) if len(position_history) > 0 else 0

    direction_changes = 0
    for i in range(1, len(dx)):
        if (dx[i] * dx[i-1] < 0) or (dy[i] * dy[i-1] < 0):
            direction_changes += 1

    print("=== Drone Hareket Analizi ===")
    print(f"Toplam uçuş mesafesi: {total_distance:.4f} birim")
    print(f"Başlangıç-bitiş arası doğrudan mesafe: {direct_distance:.4f} birim")
    print(f"Doğrusallık oranı: {linearity:.4f} (1'e yakın değerler daha doğrusal)")
    print(f"Ortalama hız: {avg_speed:.4f} birim/kare")
    print(f"Yön değişimi sayısı: {direction_changes}")

    if len(position_history) > 1:
        dx_total = x[-1] - x[0]
        dy_total = y[-1] - y[0]
        angle = np.degrees(np.arctan2(dy_total, dx_total))

        if -45 <= angle <= 45:
            direction = "Sağa"
        elif 45 < angle <= 135:
            direction = "Yukarı"
        elif angle > 135 or angle < -135:
            direction = "Sola"
        else:
            direction = "Aşağı"

        print(f"Genel hareket yönü: {direction} ({angle:.2f} derece)")

def main():
    """Ana fonksiyon"""
    print("Lütfen bir video dosyası yükleyin:")
    video_path = upload_video()
    if video_path is None:
        print("Video yüklenemedi!")
        return

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Video açılamadı: {video_path}")
        return

    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    print(f"Video FPS: {fps}")
    print(f"Video Boyutu: {frame_width}x{frame_height}")
    print(f"Toplam Kare Sayısı: {total_frames}")

    tracker = DroneMotionTracker()

    result_file = open("drone_position_results.txt", "w")
    result_file.write("Frame,X,Y,Z,Direction,Health\n")

    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter('drone_tracking.avi', fourcc, fps/3, (frame_width, frame_height))

    frame_count = 0
    start_time = time.time()
    process_interval = 2
    sample_frames = []

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_count % process_interval == 0:
            processed_frame = tracker.update_position(frame.copy())
            position = tracker.get_position()
            direction = tracker.movement_direction if tracker.movement_direction else "Belirsiz"
            health = tracker.calculate_health(frame)

            result_file.write(f"{frame_count},{position[0]:.4f},{position[1]:.4f},{position[2]:.4f},{direction},{health:.2f}\n")

            out.write(processed_frame)

            if frame_count % (process_interval * 15) == 0:
                sample_frames.append(processed_frame)

                progress = (frame_count / total_frames) * 100
                print(f"İşleniyor: %{progress:.1f} tamamlandı - Kare: {frame_count}/{total_frames}", end='\r')

        frame_count += 1

    end_time = time.time()
    processing_time = end_time - start_time
    effective_fps = frame_count / processing_time

    print("\nİşleme tamamlandı!")
    print(f"İşlenen toplam kare: {frame_count}")
    print(f"İşleme süresi: {processing_time:.2f} saniye")
    print(f"Efektif FPS: {effective_fps:.2f}")

    cap.release()
    out.release()
    result_file.close()

    print("\nÖrnek kareler gösteriliyor...")
    for i, frame in enumerate(sample_frames):
        plt.figure(figsize=(10, 8))
        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        plt.title(f"Örnek Kare {i+1}")
        plt.axis('off')
        plt.show()

    print("\nDrone hareketi grafiği oluşturuluyor...")
    plot_position_history(tracker.position_history)

    print("\nDrone hareket analizi yapılıyor...")
    analyze_trajectory(tracker.position_history)

    print("\nSonuçlar 'drone_position_results.txt' dosyasına kaydedildi.")
    files.download('drone_position_results.txt')
    files.download('drone_tracking.avi')

# Ana fonksiyonu çalıştır
main()

from google.colab import drive
drive.mount('/content/drive')